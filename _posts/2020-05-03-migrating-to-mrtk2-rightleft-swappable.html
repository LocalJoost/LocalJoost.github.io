---
layout: post
title: 'Migrating to MRTK2: right/left swappable hand menu''s for HoloLens 2'
date: '2020-05-03T18:21:00.000+02:00'
author: Joost van Schaik
tags:
- MRTK2
- Unity3D
- HoloLens2
modified_time: '2020-05-05T18:56:47.702+02:00'
thumbnail: https://i.ytimg.com/vi/5lm2z4KQTEk/default.jpg
blogger_id: tag:blogger.com,1999:blog-5295746446529817470.post-3339402343746898270
blogger_orig_url: https://dotnetbyexample.blogspot.com/2020/05/migrating-to-mrtk2-rightleft-swappable.html
---

<h2>Intro</h2><p>As I announced in <a href="https://twitter.com/LocalJoost/status/1230158501520998400" target="_blank">this tweet that you might remember from February</a> the <a href="https://www.microsoft.com/en-us/hololens" target="_blank">HoloLens</a> 2 version of my app <a href="https://www.microsoft.com/store/productId/9P6SVQQCP2SQ" target="_blank">Walk the World</a> sports two hand palm menus - a primary menu, often used command menu that is attached to your left hand that you operate with your right hand, and a secondary less-used settings menu that is attached to your right hand - and that you operate with your left. <a href="https://twitter.com/_geniodelmale" target="_blank">Lorenzo Barbieri of Microsoft Italy, a.k.a. 'Evil Scientist'</a> ;) did the brilliant suggestion I should accommodate left-handed usage as well. And so I did - I added a button to the settings menu that actually swaps the 'handedness' of the menus. This means: if you select 'left handed operation' the <em>main</em> menu is operated by your <em>left</em> hand, and the secondary <em>settings</em> menu by your <em>right</em>.</p><p>A little video makes this perhaps more clear:</p><p><iframe width="650" height="365" src="https://www.youtube.com/embed/5lm2z4KQTEk" frameborder="0" allowfullscreen="" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"></iframe></p><p>This blog explains how I made this work. I basically extracted the minimal code from my app and made it into a mini app that doesn't do more than make the menu swappable - both by pressing a toggle button and by a speech command. I will discuss the main points, but not everything in detail - but as always you can <a href="https://github.com/LocalJoost/HandmenuHandedness" target="_blank">download a full sample project</a> and see how it's working in the context of a complete running app.</p><p>This sample uses a few classes of my MRTKExtensions library of useful scripts.</p><h2>Configuring the Toolkit</h2><p>I won't cover this in much detail, but the following items need to be cloned and partially adapted:</p><ul><li>The Toolkit Configuration Profile itself (I usually start with DefaultMixedRealityToolkitConfigurationProfile). Turn off the diagnostics (as ever)</li><li>The Input System Profile</li><li>The SpeechCommandsProfile</li><li>The RegisteredServiceProviderProfile</li></ul><p>Regarding the SpeechCommandsProfile: add two speech commands:</p><ul><li>Set left hand control</li><li>Set right hand control</li></ul><p><img width="585" height="181" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20200502/03_speechcommands.png" border="0"></p><p>In the RegisteredServiceProviderProfile, register the Messenger Service that is in MRKTExtension.Messaging. If you have been following this blog, you will be familiar with this beast. I introduced this service as a Singleton behavior <a href="https://dotnetbyexample.blogspot.com/2017/04/using-messenger-to-communicate-between.html" target="_blank">back in 2017</a> and converted it to a service when the MRTK2 arrived.</p><p><img style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20200502/02_services.png" border="0"></p><h2><img align="right" style="border: 0px currentcolor; border-image: none; float: right; display: inline; background-image: none;" src="https://www.schaikweb.net/blog/20200502/04_hierarchy.png" border="0">Menu structure</h2><p>I already <a href="https://dotnetbyexample.blogspot.com/2019/11/migrating-to-mrkt2-making-hand-palm-menu.html" target="_blank">explained how to make a hand menu</a> last November,&nbsp; and in <a href="https://dotnetbyexample.blogspot.com/2020/05/migrating-to-mrkt2-easily-spacing-out.html" target="_blank">my previous blog post</a> I explained how you should arrange objects that should be laid out in a grid (like buttons). The important things to remember are:</p><ul><li>All objects that are part of a hand menu should be in a child object of the main menu object. In the sample project, this child object is called "Visuals" inside each menu.</li><li>All objects that should be easily arrangeable in a grid, should be in a separate child object within the UI itself. I always all this child object "UI", and this is where you put a GridObjectCollection behaviour on.</li></ul><p>Consistent naming makes a structure all the more recognizable I feel.</p><h2>Menu configuration</h2><p>The main palm menu has, of course, a Solver Handler and a Hand Constraint Palm Up behaviour. The tracked hand is set to the <em>left</em>.</p><p><img width="640" height="251" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20200502/05_palmmenu2.png" border="0"></p><p>The tricky thing is always to remember - the main menu is going to be <em>operated</em> by the dominant hand. For most people the dominant hand is <em>right</em> - so the hand to be <em>tracked</em> for the dominant menu is the <em>left</em> hand<em>,</em> because that leaves the <em>right</em> hand free to actually operate controls on that menu. For <em>left</em> hand control the main menu has to be set to track the <em>right</em> hand. This keeps confusing me every time.</p><p>On the palm. It won't surprise you to see the Settings menu look like this:</p><p><img width="640" height="299" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20200502/06_settingsmenu2.png" border="0"></p><p>With the Solver's TrackedHandedness set to Right. But here you also see the star of this little show: the DominantHandController, with the DominantHandController set to off - since I always have the settings menu operated by the non dominant hand, whatever that might be.</p><h2>DominantHandController</h2><p>This is actually a very simple script, that responds to messages sent from either a button or from speech commands:</p><pre style="font-size: 12px;">namespace MRTKExtensions.HandControl
{
    [RequireComponent(typeof(SolverHandler))]
    public class DominantHandHelper : MonoBehaviour
    {
        [SerializeField] 
        private bool _dominantHandControlled;
        private IMessengerService _messenger;
        private SolverHandler _solver;

        private void Start()
        {
            _messenger = MixedRealityToolkit.Instance.GetService&lt;IMessengerService&gt;();
            _messenger.AddListener&lt;HandControlMessage&gt;(ProcessHandControlMessage);
            _solver = GetComponent&lt;SolverHandler&gt;();
        }

        private void ProcessHandControlMessage(HandControlMessage msg)
        {
            var isChanged = SetSolverHandedness(msg.IsLeftHanded);
            if (msg.IsFromSpeechCommand &amp;&amp; isChanged &amp;&amp; _dominantHandControlled)
            {
                _messenger.Broadcast(new ConfirmSoundMessage());
            }
        }

        private bool SetSolverHandedness(bool isLeftHanded)
        {
            var desiredHandedness = isLeftHanded ^_dominantHandControlled ?<br>                                      Handedness.Left : Handedness.Right;
            var isChanged = desiredHandedness != _solver.TrackedHandness;
            _solver.TrackedHandness = desiredHandedness;
            return isChanged;
        }
    }
}
</pre><p>SetSolverHandedness determines what the handedness of the solver should be set to - depending on whether this menu is set to be controlled by the dominant hand or not, and whether or not left handed control is wanted. That's an XOR yes, you don't see that very often. But write out a truth table for those two parameters and that's where you will end up with. This little bit of code is what actually does the swapping of the menus from right to left and vice versa. </p><p>It also returns a value to see if the value has actually changed. This is because if the command is started from a <em>speech command</em> we want, like any good <a href="https://www.microsoft.com/en-us/windows/windows-mixed-reality" target="_blank">Mixed Reality</a> developer, give some kind of audible cue the command has been understood and processed. After all, we can say a speech command any time we want, and if the user does not have a palm up, he or she won't see hand menu flipping from one hand to the other. So only if the command comes from a speech command, <em>and</em> actual change has occurred, we need to give some kind of audible confirmation. I also added this confirmation only to be given by the <em>dominant</em> hand controller - otherwise we get a double confirmation sound. After all, there are <em>two</em> of these behaviours active - one for each menu.</p><h2>Supporting act: SettingsMenuController</h2><p>Of course, something still needs to respond to the Toggle Button being pressed. This is done by the this little behaviour:</p><pre style="font-size: 12px;">    public class SettingsMenuController : MonoBehaviour
    {
        private IMessengerService _messenger;

        [SerializeField]
        private Interactable _leftHandedButton;

        public void Start()
        {
            _messenger = MixedRealityToolkit.Instance.GetService&lt;IMessengerService&gt;();
            gameObject.SetActive(CapabilitiesCheck.IsArticulatedHandSupported);
            _messenger.AddListener&lt;HandControlMessage&gt;(ProcessHandControlMessage);
        }

        private void ProcessHandControlMessage(HandControlMessage msg)
        {
            if (msg.IsFromSpeechCommand)
            {
                _leftHandedButton.IsToggled = msg.IsLeftHanded;
            }
        }

        public void SetMainDominantHandControl()
        {
            SetMainDominantHandDelayed();
        }

        private async Task SetMainDominantHandDelayed()
        {
            await Task.Delay(100);
            _messenger.Broadcast(new HandControlMessage(_leftHandedButton.IsToggled));
        }
    }
}</pre><p>The SetMainDominantHandControl is called from the OnClick event in the Interactable behaviour on the toggle button:</p><p><img style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20200502/07_event.png" border="0"></p><p>and then simply fires off the message based upon the toggle status of the button. Note that there's a slight delay, this has two reasons:</p><ol><li>Make sure the sound the button plays actually has time to play</li><li>Make sure the button's IsToggled is actually set to the right value before we fire off the message. </li></ol><p>Yeah, I know, it's dicey but that's how it apparently needs to work. Also note this little script not only fires off HandControlMessage but also <em>listens</em> to it. After all, if someone changes the handedness by speech commands, we want to see the button's toggle status reflect the actual status change.</p><h2>Some bits and pieces</h2><p>The final piece of code - that I only mention for the sake of completeness - is SpeechCommandProcessor :</p><pre style="font-size: 12px;">namespace HandmenuHandedness
{
    public class SpeechCommandProcessor : MonoBehaviour
    {
        private IMessengerService _messenger;

        private void Start()
        {
            _messenger = MixedRealityToolkit.Instance.GetService&lt;IMessengerService&gt;();
        }

        public void SetLeftHanded(bool isLeftHanded)
        {
            _messenger.Broadcast(new HandControlMessage(isLeftHanded) <br>                                                        { IsFromSpeechCommand = true });
        }
    }
}</pre><p>It sits together with a SpeechInputHandler in Managers:</p><p><img width="640" height="141" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20200502/08_speech.png" border="0"></p><p>Just don't forget to turn <em>off</em> the "Is Focus Required" checkbox as these are global speech commands. Itned to forget this, and that makes for an amusing few minutes of shouting to your HoloLens without it having any effect, before the penny drops.</p><h2>Conclusion</h2><p>You might have noticed I don't let the menu's appear <em>on</em> your hand anymore but <em>next to </em>your hand. This comes from the design guidelines on hand menu's on the official MRKT2 documentation, and although I can have a pretty strong opinion about things, I do tend to take some advice occasionally ;) - especially when it's about usability and ergonomics. Which is exactly why I made this left-to-right swappability in the first place. I hope this little blog post will give people some tools to add a little bit to inclusivity for HoloLens 2 applications.</p><p><a href="https://github.com/LocalJoost/HandmenuHandedness" target="_blank">Full project, as mostly always, here on GitHub.</a></p>