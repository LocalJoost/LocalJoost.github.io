---
layout: post
title: Migrating to MRTK2– handling tap, touch and focus ‘manually’ (in code)
date: '2019-07-09T09:30:00.000+02:00'
author: Joost van Schaik
tags:
- HoloLens
- Unity
- Windows Mixed Reality
- MRTK2
- HoloLens2
modified_time: '2019-07-10T10:58:51.932+02:00'
blogger_id: tag:blogger.com,1999:blog-5295746446529817470.post-908061367877703036
blogger_orig_url: https://dotnetbyexample.blogspot.com/2019/07/migrating-to-mrtk2-handling-tap-touch.html
---

<h2>Wait a minute – you did handle tap before, right?</h2><p>Indeed, dear reader, I did. But I also had signed up for a <a href="https://www.mixug.com/" target="_blank">MixUG</a> <a href="https://twitter.com/mixugnl/status/1146464058733998080" target="_blank">session on Wednesday July 3</a>. And while making demos for that I learned some other ways to handle interaction. Once again it shows that the best way to learn things is to try to teach them – because the need to explain things induces the need to actually obtain a deeper knowledge.</p><h2>Ye olde way</h2><p>In the MRTK 1, it was thus:</p><ul><li>Handle tap – implement IInputClickHandler</li><li>Handle drag – implement IManipulationHandler</li><li>Handle focus – implement <br></li><li>Handle touch – forget it. ;)</li></ul><h2>The new way </h2><p>In the MRTK 2 it is now</p><ul><li>Handle tap – implement IMixedRealityPointerHandler</li><li>Handle drag – see above</li><li>Handle focus – implement IMixedRealityFocusHandler</li><li>Handle touch – IMixedRealityTouchHandler</li></ul><p>Now I am going to ignore drag for this tutorial, and concentrate me on tap, focus and touch</p><h2>IMixedRealityPointerHandler</h2><p>This requires you to implement four methods:</p><ul><li>OnPointerDown</li><li>OnPointerDragged</li><li>OnPointerUp</li><li>OnPointerClicked</li></ul><p>OnPointerClicked basically intercept a tap or an air tap, and will work as such as you deploy the <a href="https://github.com/LocalJoost/ClickTouchFocus" target="_blank">demo project</a> to a <a href="https://www.microsoft.com/en-us/hololens" target="_blank">HoloLens</a> 1. After being bitten by people tapping just a tiny bit to slow and therefore not getting response, I tend to implement OnPointerDown rather than OnPointerClicked to capture a 'tap' event, but that's a matter of preference.</p><h2>IMixedRealityFocusHandler</h2><p>You will need to implement:</p><ul><li>OnFocusEnter</li><li>OnFocusExit</li></ul><p>The method names are the same as in MRKT1, only the signatures not - you now get a parameter of type FocusEventData which does give you some more information - by what the object was focused (we have multiple ways of doing that now!), what the previous focused object was, and what the new focused object is.</p><h2>IMixedRealityTouchHandler</h2><p>This requires you to implement </p><ul><li>OnTouchStarted</li><li>OnTouchCompleted</li><li>OnTouchUpdated</li></ul><p>But there is a twist to that. As we will soon see.</p><h2>Show-off</h2><p>To show off how it all works, I have created <a href="https://github.com/LocalJoost/ClickTouchFocus" target="_blank">a little demo project</a>. You can run it either in the emulator or the Unity editor (or a HoloLens 2, if you are in the HoloLens team and part some very few selected parties - I am unfortunately neither).</p><p>I have created a little script <a href="https://github.com/LocalJoost/ClickTouchFocus/blob/master/Assets/App/Scripts/CodedInteractionResponder.cs" target="_blank">CodedInteractionResponder</a> that shows off how this works. This script implements all the three interfaces I just wrote about. If you open the demo project in Unity show itself like this. All three cubes have the script attached to them.</p><p><img width="640" height="260" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20190710/Demo1.png" border="0"></p><p>The text above the cubes will show how much times a cube has been either focused, touched or clicked. I you press play and then the space bar, the right hand will appear (or use ctrl for the left hand). Moving the hand can be done by using the mouse - if you move the hand ray over the cubes it will trigger a focus event, if you tap the left mouse button you will trigger a tap, and if you move the hand towards the cube (using the WASD keys) it will trigger a touch event.</p><p><img width="640" height="331" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20190710/Demo2.png" border="0"></p><p>That is to say - you would expect that. But that is not always the case</p><p>What happens is this:</p><ul><li>You can click or focus the green cube, but you cannot touch it. Nothing happens if you try.</li><li><div align="left">You can click, focus or touch the red cube, but if you touch it, the number of times it's <em>clicked</em> is increasing. Not the number of touches.</div></li><li>Only the blue cube works as expected.</li></ul><p>Yet they all have the CodedInteractionResponder. How does this compute?</p><h2>NearInteractionTouchable</h2><p>The best way to explain this, is an image showing the bottom half of all the three cubes</p><p><img width="640" height="225" style="border: 0px currentcolor; border-image: none; background-image: none;" src="https://www.schaikweb.net/blog/20190710/threecubes.png" border="0"></p><p>The green cube misses the NearInteractionTouchable. This script is necessary to have touch events being fired at all. So unlike IMixedRealityPointerHandler and IMixedRealityFocusHandler, where a mere implementation of the interface will trigger an event, a <em>touch</em> event - that is, methods in IMixedRealityTouchHandler being called - <em>requires the addition of a NearInteractionTouchable script</em><strong>.</strong></p><p>And NearInteractionTouchable has another trick up it's sleeve. Suppose you have a button - whether it's (air) tapped or actually touched/pressed, you want to activate the same code. If you change "Events to Receive" from it's default "Touch" to "Pointer" (as I did with the red cube) touching the cube will actually trigger a pointer event. This saves you a few lines of code. So basically NearInteractionTouchable can act as a kind of event router. And this is why the red cube never shows a touch event - but a click event instead.</p><p>Be aware NearInteractionTouchable<em> needs a collider to work on</em>. This collider needs to be on the same object the script is on. So if you make an empty game object as a hat stand for a a bunch of smaller game objects, make sure to manually add a collider that envelops all game objects, otherwise the 'touch' won't seem to work.</p><h2>What, no code?</h2><p>Yes, there is code, but it's pretty straightforward and if you want to have a look at <a href="https://github.com/LocalJoost/ClickTouchFocus/blob/master/Assets/App/Scripts/CodedInteractionResponder.cs" target="_blank">CodeInteractionResponder</a>, have a look in GitHub. It's actually so simple I felt it a little bit overdone to verbatim repeat parts in this blog post itself.</p>